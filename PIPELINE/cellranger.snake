# ===== Snakemake rules for running the 10x Cell Ranger pipeline ===============


# Merge fastqs and create symlinks =============================================
# This rule will either merge multiple fastqs into a single file or create a 
# symlink to the original fastq. If a comma separated list of sample names is 
# provided all fastqs that begin with either name will be merged into one file 
# that has a new name. If only a single name is provided a symlink will be 
# created for each fastq that begins with the name.

rule merge_fastqs:
    output:
        "{results}/logs/merge_fastqs.out"
    params:
        job_name = "merge_fastqs",
        raw_data = RAW_DATA,
        fq_regex = FASTQ_REGEX,
        rna      = RNA_SAMPLES,
        adt      = ADT_SAMPLES,
        vdj      = VDJ_SAMPLES
    log:
        "{results}/logs/merge_fastqs"
    threads:
        1
    run:
        # Function to retrieve fastq paths
        def _get_fq_paths(sample, read):
            path_list = []

            for dir in params.raw_data:
                fq_paths = os.path.join(dir, sample + "*" + read + "*.fastq.gz") 
                fq_paths = glob.glob(os.path.abspath(fq_paths))

                if fq_paths:
                    [path_list.append(x) for x in fq_paths]

            if not path_list:
                sys.exit("ERROR: No fastqs found for " + sample + ".") 
                          
            return path_list

        # Function to build merge command
        def _build_merge_cmd(path_list, merged_path):
            cmds = ""

            for fq_path in path_list:
                cmds += " " + fq_path

            cmds = "cat" + cmds + " > " + merged_path

            return cmds

        # Function to merge fastq files or create symlink
        def _merge_fastqs(sample, merged_name):

            # Merge fastqs for each read
            for read in ["_R1_", "_R2_"]:
                names = sample.split(",")

                # Create list of commands for merging fastqs
                path_list = []

                for name in names:
                    [path_list.append(x) for x in _get_fq_paths(name, read)]

                fq_info     = re.search(params.fq_regex, path_list[0]).group(0)
                merged_path = os.path.join(params.raw_data, merged_name + fq_info)
                cmd_list    = [_build_merge_cmd(path_list, merged_path)]  

                for cmd in cmd_list:
                    subprocess.run(cmd, shell = True)

        # Merge CITE-seq and cell hashing fastqs
        if params.adt:
            merged_names = [re.sub(",", "_", x) for x in params.adt]

            [_merge_fastqs(x, y) for x, y in zip(params.adt, merged_names)]

        # Write output file
        with open(output[0], "w") as out:
            out.write("done\n")



# Create antibody csv ==========================================================
# This rule creates a csv file used by cellranger count that contains the 
# antibody names, barcode sequences, and barcode position.

rule create_ab_csv:
    input:
        "{results}/logs/merge_fastqs.out"
    output:
        "{results}/logs/antibody_csv.out"
    params:
        job_name = "antibody_csv",
        results  = RESULTS,
        adt      = ADT_SAMPLES,
        adt_ref  = ADT_REF,
        abs      = ANTIBODIES
    log:
        "{results}/logs/antibody_csv"
    threads:
        1
    run:
        if params.adt:
            ab_csv = params.results + "/antibodies.csv"

            if params.abs:
                # Open output csv
                with open(ab_csv, "w") as ab_csv:
                    ab_csv.write("id,name,read,pattern,sequence,feature_type\n")
                
                    # Iterate through antibody list
                    for ab in params.abs:
                        ab_regex = ".+_" + ab + ",.+"
                        match    = False

                        # Search for antibody in reference
                        for line in open(params.adt_ref):
                            ab_match = re.search(ab_regex, line)

                            if ab_match:
                                ab_csv.write(ab_match.group(0) + "\n")

                                if match:
                                    sys.exit("ERROR: " + ab + " matches multiple entries in the reference file.")

                                match = True

                        if not match:
                            sys.exit("ERROR: " + ab + " was not found in the reference file.")

            else:
                shutil.copyfile(params.adt_ref, ab_csv)

        # Write output file
        with open(output[0], "w") as out:
            out.write("done\n")



# Create sample csv ============================================================
# This rule creates a csv file used by cellranger count that contains the path 
# to the fastq directory, each fastq prefix, and the library type.

rule create_sample_csv:
    input:
        "{results}/logs/antibody_csv.out"
    output:
        "{results}/logs/{sample}_csv.out"
    params:
        job_name = "sample_csv",
        results  = RESULTS,
        raw_data = RAW_DATA,
        fq_regex = FASTQ_REGEX,
        rna      = RNA_SAMPLES,
        adt      = ADT_SAMPLES
    log:
        "{results}/logs/{sample}_csv"
    threads:
        1
    run:
        # Function to create sample csv file for cellranger count
        def _create_sample_csv(sam_name, lib_type, sam_csv):
            fq_path = os.path.join(params.raw_data, sam_name + "*.fastq.gz")
            fastqs  = glob.glob(fq_path)
            R1_fqs  = [x for x in fastqs if "_R1_" in x]

            # Trim fastq names
            R1_fqs = [os.path.basename(x) for x in R1_fqs]
            R1_fqs = [re.sub(params.fq_regex, "", x) for x in R1_fqs]

            # Create sample csv
            if not os.path.isfile(sam_csv):
                with open(sam_csv, "w") as csv:
                    csv.write("fastqs,sample,library_type\n")

            with open(sam_csv, "a") as csv:
                for fq in R1_fqs:
                    csv.write("%s,%s,%s\n" % (params.raw_data, fq, lib_type))

        # Create sample csv file for cellranger count
        sample_csv = os.path.join(params.results, wildcards.sample + ".csv")

        if os.path.isfile(sample_csv):
            os.remove(sample_csv)

        if params.rna and params.adt:
            rna_id, adt_id = wildcards.sample.split("-")
            _create_sample_csv(rna_id, "Gene Expression", sample_csv)
            _create_sample_csv(adt_id, "Antibody Capture", sample_csv)

        elif params.rna:
            _create_sample_csv(wildcards.sample, "Gene Expression", sample_csv)

        elif params.adt:
            _create_sample_csv(wildcards.sample, "Antibody Capture", sample_csv)

        # Write output file
        with open(output[0], "w") as out:
            out.write("done\n")



# Run cellranger count =========================================================
# This rule runs cellranger count using csv files from create_sample_csv and 
# create_ab_csv.

rule cellranger_count:
    input:
        "{results}/logs/{sample}_csv.out"
    output:
        "{results}/logs/{sample}_count.out"
    params:
        job_name = "count",
        results  = RESULTS,
        rna      = RNA_SAMPLES,
        adt      = ADT_SAMPLES,
        rna_ref  = RNA_REF,
    log:
        "{results}/logs/{sample}_count"
    threads:
        JOB_THREADS
    resources:
        mem_gb = JOB_MEM
    run:
        # Run cellranger count for CITE-seq and gene expression
        if params.adt:
            shell(
                """
                sample_csv={wildcards.sample}.csv
                ab_csv=antibodies.csv

                cd {params.results}

                {CELLRANGER} count \
                    --id={wildcards.sample} \
                    --jobmode=local \
                    --libraries=$sample_csv \
                    --feature-ref=$ab_csv \
                    --project="scRNA-seq" \
                    --transcriptome={params.rna_ref} \
                    --localcores={threads} \
                    --localmem={resources.mem_gb}
                """
            )

        # Run cellranger count just for gene expression
        elif params.rna:
            shell(
                """
                sample_csv={wildcards.sample}.csv

                cd {params.results}

                {CELLRANGER} count \
                    --id={wildcards.sample} \
                    --jobmode=local \
                    --libraries=$sample_csv \
                    --project="scRNA-seq" \
                    --transcriptome={params.rna_ref} \
                    --localcores={threads} \
                    --localmem={resources.mem_gb}
                """
            )

        # Copy output files to outer directory
        if params.rna or params.adt:
            sample  = params.results + "/" + wildcards.sample
            out_dir = os.path.join(sample, outs)

            shutil.copyfile(out_dir + "/web_summary.html", sample + ".html")
            shutil.copyfile(out_dir + "/cloupe.cloupe", sample + ".cloupe")
            shutil.copytree(out_dir + "/filtered_feature_bc_matrix", sample + "_filtered_feature_bc_matrix")
        
        # Write output file
        with open(output[0], "w") as out:
            out.write("done\n")



# Run cellranger vdj ===========================================================
# This rule generates IDs for VDJ fastqs and runs cellranger vdj.

def _get_fq_ids(wildcards):
    fqs    = glob.glob(os.path.join(RAW_DATA, wildcards.vdj_sample + "*"))
    R1_fqs = [x for x in fqs if "R1" in x]
    R1_fqs = [os.path.basename(x) for x in R1_fqs]

    fq_ids = set()

    for fq in R1_fqs:
        fq_id = re.sub(FASTQ_REGEX, "", fq)
        fq_ids.add(fq_id)
    
        if not re.search(FASTQ_REGEX, fq):
            sys.exit("ERROR: Unable to parse sample ID for " + fq + ".")

    return ",".join(fq_ids)


rule cellranger_vdj:
    input:
        "{results}/logs/merge_fastqs.out"
    output:
        "{results}/logs/{vdj_sample}_vdj.out"
    params:
        job_name = "vdj",
        fq_ids   = _get_fq_ids,
        results  = RESULTS,
        raw_data = RAW_DATA,
        vdj      = VDJ_SAMPLES,
        vdj_ref  = VDJ_REF
    log:
        "{results}/logs/{vdj_sample}_vdj"
    threads:
        JOB_THREADS
    resources:
        mem_gb = JOB_MEM
    run:
        # Run cellranger vdj
        if params.vdj:
            shell(
                """
                cd {params.results}

                cellranger vdj \
                    --id={wildcards.vdj_sample} \
                    --fastqs={params.raw_data} \
                    --sample={params.fq_ids} \
                    --reference={params.vdj_ref} \
                    --localcores={threads} \
                    --localmem={resources.mem_gb}
                """
            )
        
            # Copy output files to outer directory
            sample  = params.results + "/" + wildcards.sample
            out_dir = os.path.join(sample, outs)

            shutil.copyfile(out_dir + "/web_summary.html", sample + ".html")
            shutil.copyfile(out_dir + "/vloupe.vloupe", sample + ".vloupe")
        
        # Write output file
        with open(output[0], "w") as out:
            out.write("done\n")



