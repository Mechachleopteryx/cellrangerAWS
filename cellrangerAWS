#! /bin/bash

set -x -o nounset -o pipefail -o errexit


# Inputs
AWS_USER="none"
PROJECT="cellranger"
INPUT="none"
CONFIG="none"
S3="none"
KEY="none"
TRANSFER_DATA=true

#EC2_TYPE="c5.12xlarge"
EC2_TYPE="t2.2xlarge"
AMI="ami-0a5271f1933bebca3"
MANUAL_MODE=false

ZONE="us-west-2a"
SECURITY_GROUP="sg-00cf9318d9719735d"
SUBNET="subnet-083a3a855e543ee1c"
EC2_USER="ubuntu"


# Usage message
usage() {
    echo """
USAGE
"$0" [OPTIONS]

OPTIONS
-h, display this message.

-i, path to local directory or S3 bucket containing fastq files.
-c, path to config.yaml ...OR S3 BUCKET.
-s, name of S3 bucket.
-n, AWS user name.

-k, path to AWS private key.
-t, EC2 instance type (default is "$EC2_TYPE").
-a, ID for machine image configured to run cellranger (default is "$AMI").
-m, run in manual mode, this transfers data to an EC2 instance and exits.
    """
}





# Parse arguments =============================================================

while getopts ":hi:c:s:n:k:t:p:a:m" args
do
    case "$args" in
        h)
            usage
            exit 0
            ;;
        i) 
            INPUT="$OPTARG"

	    if [[ "$INPUT" =~ ^s3://.+ ]]
            then
                TRANSFER_DATA=false
		S3="$INPUT"
            fi
            ;;
        c)
            CONFIG="$OPTARG"
            ;;
        s)
            S3="$OPTARG"
            ;;
        n)
            AWS_USER="$OPTARG"
            ;;
        k)
            KEY="$OPTARG"
            ;;
        t)
            EC2_TYPE="$OPTARG"
            ;;
        p)
            PROJECT="$OPTARG"
            ;;
        a)
            AMI="$OPTARG"
            ;;
        m)
            MANUAL_MODE=true
            ;;
        :)
            echo -e "\nERROR: -$OPTARG requires an argument"

            usage
	    exit 1
            ;;
	*) 
            usage
	    exit 1
            ;;
    esac
done

if [[ "$INPUT" == "none" || "$CONFIG" == "none" || "$KEY" == "none" || "$AWS_USER" == "none" || "$S3" == "none" ]]
then
    echo -e "\nERROR: Arguments are required for -i, -c, -o, and -k."

    usage
    exit 1
fi





# Check instance/volume status ================================================

check_status() {
    local input_fun="$1"
    local id="$2"
    local num=60

    if [[ $# == 3 ]]
    then
        local num="$3"
    fi

    echo -e "\nChecking for $input_fun $id..."

    for i in $(seq 1 "$num")
    do
        if "$input_fun" "$id" | grep --quiet "$id"
        then
            return 0
        fi

        sleep 10
    done

    echo -e "\nERROR: Timed out waiting for $input_fun $id."

    exit 1
}





# Transfer data to S3 bucket ===================================================

transfer_to_s3() {
    local input="$1"
    local s3="$2"

    if ! aws s3 ls "$s3" > /dev/null
    then
        bucket_name=$(echo "$s3" | sed 's/s3:\/\///g')

        aws s3api create-bucket \
            --bucket "$bucket_name"
    fi

    for fq in "$input"*.fastq.gz
    do
        aws s3 cp "$fq" "$s3"
    done
}





# Launch EC2 instance ==========================================================
# When using default VPC the instance does not have internet access. To resolve
# this create new VPC, security group, subnet, and internet gateway. Activate
# public IP for subnet, activate public DNS for VPC, attach VPC to internet
# gateway, modify route table for VPC.

launch_ec2() {
    local ami="$1"
    local ec2_type="$2"
    local zone="$3"
    local security_group="$4"
    local subnet="$5"
    local key_name=$(basename -s .pem "$KEY")

    echo -e "\nLaunching EC2 $EC2_TYPE instance..."



    # Launch EC2 instance
    # Public DNS is not listed in run-instances output, this must be retrieved
    # separately
    ec2_id=$(
        aws ec2 run-instances \
            --instance-type "$ec2_type" \
            --image-id "$ami" \
            --placement AvailabilityZone="$zone" \
            --security-group-ids "$security_group" \
            --subnet-id "$subnet" \
            --key-name "$key_name" \
            --associate-public-ip-address \
            | grep -E -o "InstanceId\": \"i\-[[:alnum:]]+" \
            | grep -E -o "i\-[[:alnum:]]+"
    )

    running_ec2() {
        aws ec2 describe-instances \
            --instance-id "$1" \
            --filters Name=instance-state-name,Values=running
    }

    check_status running_ec2 "$ec2_id"

    echo -e "\nEC2 instance $ec2_id has been successfully launched."
}





# Retrieve public DNS for EC2 instance and check connectivity ==================

get_dns() {
    local ec2="$1"

    echo -e "\nAttempting to make contact with EC2 instance $ec2..."



    # Retrieve public IP to check connectivity
    local ip=$(
        aws ec2 describe-instances \
            --instance-id "$ec2" \
            | grep -E "PublicIpAddress" \
            | grep -E -o "[0-9\.]+"
    )



    # Ping IP
    for i in $(seq 1 20)
    do
        local packet_loss=$(
            ping -c 10 "$ip" \
                | grep -E -o "[0-9]+% packet loss" \
                | grep -E -o "[0-9]+"
        )

        # If IP responds to ping, return public DNS
        if [[ "$packet_loss" < 100 ]]
        then
            local dns=$(
                aws ec2 describe-instances \
                    --instance-id "$ec2" \
                    | grep -E -o "ec2\-[[:alnum:]\.\-]+compute.amazonaws.com" \
                    | head -n 1
            )

            EC2_SSH="$EC2_USER@$dns"

            echo -e "\nConnection has been established with EC2 instance $ec2."
	    echo "Use the following command to manually connect to the instance:"
	    echo "ssh -i $KEY $EC2_SSH"

            return 0
        fi
    done



    # If IP does not respond to ping, terminate instance
    aws ec2 terminate-instances \
        --instance-ids "$ec2"

    echo -e "ERROR: Unable to connect, terminating EC2 instance $ec2..."

    exit 1
}





# Create and mount EBS volume on EC2 instance ==================================

create_ebs() {
    local input=$1
    local ec2=$2
    local zone=$3

    echo -e "Creating EBS volume..."



    # Get total file size
    local data_size=$(
        aws s3 ls s3://rbifellows/ --summarize --human-readable \
            | grep "Total Size" \
            | grep -E -o "[0-9]+.+$"
    )

    local vol_size=$(
        echo "$data_size" \
            | grep -E "^[0-9]"
    )

    local vol_size=$(expr "$vol_size" \* 2)

    if ! echo "$data_size" | grep -E "GiB|TiB" --quiet
    then
        local vol_size=10
    fi

    if [[ "$vol_size" < 10 ]]
    then
        local vol_size=10
    fi



    # Get list of attached devices, need this to identify attached EBS volume
    local old_devs=$(
        ssh -o "StrictHostKeyChecking no" -i "$KEY" "$EC2_SSH" \
            sudo fdisk -l \
                | grep -E -o "/dev/[[:alnum:]]+" \
                2>&1
    )

    # Keep old_devs unquoted here
    local old_devs=$(
        echo $old_devs \
            | sed 's/ /|/g'
    )



    # Create EBS volume
    vol_id=$(
        aws ec2 create-volume \
            --size "$vol_size" \
            --availability-zone "$zone" \
            | grep -E -o "vol\-[[:alnum:]]+"
    )

    available_vol() {
        aws ec2 describe-volumes \
            --volume-ids "$1" \
            --filters Name=status,Values=available
    }

    check_status available_vol "$vol_id"



    # Attach EBS volume
    aws ec2 attach-volume \
        --instance-id "$ec2" \
        --volume-id "$vol_id" \
        --device /dev/sdh \
        > /dev/null

    attached_vol() {
        aws ec2 describe-volumes \
            --volume-ids "$1" \
            --filters Name=attachment.status,Values=attached
    }

    check_status attached_vol "$vol_id"



    # Identify device path for EBS volume
    local new_devs=$(
        ssh -i "$KEY" "$EC2_SSH" \
            sudo fdisk -l \
                | grep -E "^Disk .+$vol_size GB" \
                | grep -E -o "/dev/[[:alnum:]]+" \
                2>&1
    )
    
    local dev_path=$(
        echo "$new_devs" \
            | grep -E -v "$old_devs"
    )



    # Format and mount EBS volume
    ssh -i "$KEY" "$EC2_SSH" bash <<EOF
        sudo parted "$dev_path" mklabel gpt > /dev/null 2>&1
        sudo parted -a opt "$dev_path" mkpart primary ext4 0% 100% > /dev/null 2>&1
        sudo mkfs.ext4 -F "$dev_path" > /dev/null 2>&1

        sudo mkdir -p /mnt/EBS
        sudo mount "$dev_path" /mnt/EBS
        sudo mkdir -p /mnt/EBS/DATA
        sudo chmod -R 777 /mnt/EBS
EOF

    echo -e "\nEBS volume $vol_id ($vol_size GB) was created and mounted to EC2 instance $ec2."
}





# Transfer data from S3 to EBS volume ==========================================

transfer_to_ec2() {
    local aws_user="$1"
    local s3="$2"



    # Install and configure AWS on EC2 instance
    local user_info=$(
        aws iam create-access-key \
            --user-name "$aws_user"
    )

    local secret_key=$(
        echo "$user_info" \
            | grep "SecretAccessKey" \
	    | cut -d ":" -f 2 \
	    | sed 's/[\",]//g'
    )

    local key_id=$(
        echo "$user_info" \
            | grep "AccessKeyId" \
            | cut -d ":" -f 2 \
            | sed 's/[\".]//g'
    )

    ssh -i "$KEY" "$EC2_SSH" \
        pip3 install awscli --upgrade

    wait

    ssh -i "$KEY" "$EC2_SSH" bash <<EOF
        aws configure set aws_secret_access_key "$secret_key"
        aws configure set aws_access_key_id "$key_id"
EOF



    # Transfer fastqs to EBS volume
    local s3_fqs=$(
        aws s3 ls "$s3" \
            | grep -E -o "[[:alnum:]_\-\.]+.fastq.gz"
    )

    # Leave s3_fqs unquoted
    for fq in $s3_fqs
    do 
        ssh -i "$KEY" "$EC2_SSH" \
            aws s3 cp "$s3/$fq" /mnt/EBS/DATA
    done

    wait
}





# Terminate EC2 instance and delete EBS volume ======

terminate_ec2() {
    local ec2="$1"
    local vol="$2"



    # Terminate EC2 instance
    echo -e "\nTerminating EC2 instance $ec2..."

    aws ec2 terminate-instances \
        --instance-ids "$ec2" \
        > /dev/null

    terminated_ec2() {
        aws ec2 describe-instances \
            --instance-id "$1" \
            --filters Name=instance-state-name,Values=terminated
    }

    check_status terminated_ec2 "$ec2"



    # Delete EBS volume
    echo -e "\nDeleting EBS volume $vol..."

    aws ec2 delete-volume \
        --volume-id "$vol" \
        > /dev/null

    echo -e "\nEC2 instance $ec2_id has been terminated and EBS volume $vol_id has been deleted."
}





# Main function ================================================================

main() {
  
    # Set project name
    project_name="$PROJECT"_$(date +%Y%m%d-%H%M%S)



    # Transfer data to S3 bucket
    if "$TRANSFER_DATA"
    then
        transfer_to_s3 \
            "$INPUT" \
            "$S3"
    fi



    # Launch EC2 instance and retrieve ec2_id
    launch_ec2 \
        "$AMI" \
        "$EC2_TYPE" \
        "$ZONE" \
        "$SECURITY_GROUP" \
        "$SUBNET"



    # Check EC2 instance connectivity and retrieve EC2_SSH
    get_dns "$ec2_id"



    # Create EBS volume and retrieve vol_id
    create_ebs \
        "$INPUT" \
        "$ec2_id" \
        "$ZONE"



    # Transfer data from S3 bucket to EC2 instance
    transfer_to_ec2 \
        "$AWS_USER" \
        "$ec2_id"

    if "$MANUAL_MODE"
    then
        exit 0
    fi



    # Run cellranger and transfer results to S3 bucket
    echo -e "\nBeginning Cell Ranger run..."

    ssh -i "$KEY" "$EC2_SSH" \
        bash "/home/$EC2_USER/PIPELINE/snakecharmer.sh"

    echo -e "\nCell Ranger run has completed, transferring results to S3 bucket $S3."
    
    ssh -i "$KEY" "$EC2_SSH" \
        aws s3 cp /mnt/EBS/RESULTS "$S3" --recursive



    # Terminate EC2 instance
    if [[ "$EC2_ID" == "none" ]]
    then
        terminate_ec2 \
            "$ec2_id" \
            "$vol_id"
    fi
}



main



