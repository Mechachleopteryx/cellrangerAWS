#! /bin/bash

set -x -o pipefail



# Inputs
PROJECT="cellranger"
EC2_TYPE="t2.2xlarge"
AMI="ami-0b223f110bbbd4a9e"
VOLUME_SIZE=300
CREATE_VOL=true
ZONE="us-west-2a"
SECURITY_GROUP="sg-00cf9318d9719735d"
SUBNET="subnet-083a3a855e543ee1c"
USER="ubuntu"



# Usage message
usage() {
    echo """

USAGE
$0 [OPTIONS]

OPTIONS
-h, display this message
-i, input directory containing fastq files and config.yaml or ID for snapshot containing data
-o, output directory
-p, project name
-k, path to AWS private key
-t, EC2 instance type (default is $EC2_TYPE)
-s, size of EBS volume (default is $VOLUME_SIZE GB)
-a, ID for machine image configured to run cellranger (default is $AMI)

    """
}



# Parse arguments
while getopts ":hi:o:p:k:t:s:a:" args
do
    case "$args" in
        h)
            usage
            exit 0
            ;;
        i) 
            INPUT="$OPTARG"

	    if [[ "$INPUT" =~ ^snap\-[[:alnum:]]+$ ]]
            then
                CREATE_VOL=false
            fi
            ;;
        o)
            OUTPUT="$OPTARG"
            ;;
        p)
            PROJECT="$OPTARG"
            ;;
        k)
            KEY="$OPTARG"
            ;;
        t)
            EC2_TYPE="$OPTARG"
            ;;
        s)
            VOLUME_SIZE="$OPTARG"
            ;;
        a)
            AMI="$OPTARG"
            ;;
        :)
            echo -e "\nERROR: -$OPTARG requires an argument"

            usage
	    exit 1
            ;;
	*) 
            usage
	    exit 1
            ;;
    esac
done

if [[ -z "$INPUT" || -z "$OUTPUT" || -z "$KEY" ]]
then
    echo -e "\nERROR: arguments are required for -i, -o, and -k"

    usage
    exit 1
fi



# Check instance/volume state
check_state() {
    local input_fun=$1

    for i in $(seq 1 60)
    do
        state=$("$input_fun")

        if [[ ! -z "$state" ]]
        then
            break
        fi

	if [[ i == 60 ]]
        then
            echo -e "\nERROR: could not find $input_fun\n"

            exit 1
        fi

        sleep 5
    done
}



# Launch EC2 instance
# When using default VPC the instance does not have internet access. To resolve
# this create new VPC, security group, subnet, and internet gateway. Activate
# public IP for subnet, activate public DNS for VPC, attach VPC to internet
# gateway, modify route table for VPC.

launch_ec2() {
    local ami="$1"
    local ec2_type="$2"
    local zone="$3"
    local security_group="$4"
    local subnet="$5"
    local key_name=$(basename -s .pem "$KEY")

    # Launch EC2 instance
    local ec2=$(
        aws ec2 run-instances \
            --instance-type "$ec2_type" \
            --image-id "$ami" \
            --placement AvailabilityZone="$zone" \
            --security-group-ids "$security_group" \
            --subnet-id "$subnet" \
            --key-name "$key_name" \
            --associate-public-ip-address \
            | grep -E -o "InstanceId\": \"i\-[[:alnum:]]+" \
            | grep -E -o "i\-[[:alnum:]]+"
    )

    running_ec2() {
        aws ec2 describe-instances \
            --instance-id "$ec2" \
            --filters Name=instance-state-name,Values=running \
            | grep -o "$ec2"
    }

    check_state running_ec2


    # Return ID for launched EC2 instance
    echo "$ec2"
}



create_ebs() {
    local ec2=$1
    local volume_size=$2
    local zone=$3


    # Create EBS volume
    if [[ "$CREATE_VOL" == true ]]
    then
        local vol=$(
            aws ec2 create-volume \
                --size "$volume_size" \
                --availability-zone "$zone" \
                | grep -E -o "vol\-[[:alnum:]]+"
        )

    else
        local vol=$(
            aws ec2 create-volume \
                --snapshot-id "$INPUT" \
                --availability-zone "$zone" \
	        | grep -E -o "vol\-[[:alnum:]]+"
        )
    fi

    available_vol() {
        aws ec2 describe-volumes \
            --volume-ids "$vol" \
            --filters Name=status,Values=available \
            | grep -o "$vol"
    }

    check_state available_vol


    # Attach EBS volume
    aws ec2 attach-volume \
        --instance-id "$ec2" \
        --volume-id "$vol" \
        --device /dev/sdh \
        > /dev/null

    attached_vol() {
        aws ec2 describe-volumes \
            --volume-ids "$vol" \
            --filters Name=attachment.status,Values=attached \
            | grep -o "$vol"
    }

    check_state attached_vol

    sleep 60


    # Return ID for attached EBS volume
    echo "$vol"
}



transfer_data() {
    local input="$1"
    local vol="$2"
    local volume_size="$3"
    local ssh="$4"
    local snap_name="$5"


    # Retrieve device path for EBS volume
    dev_path=$(
        ssh -o "StrictHostKeyChecking no" -i "$KEY" "$ssh" \
            sudo fdisk -l \
                | grep -E -o "^Disk .+$volume_size GiB" \
                | grep -E -o "/dev/[[:alnum:]]+" \
                2>&1
    )


    # Format new EBS volume
    if [[ "$CREATE_VOL" == true ]]
    then
        ssh -o "StrictHostKeyChecking no" -i "$KEY" "$ssh" bash <<EOF
            sudo parted "$dev_path" mklabel gpt
	    sudo parted -a opt "$dev_path" mkpart primary ext4 0% 100%
	    sudo mkfs.ext4 -F "$dev_path"
EOF

    fi


    # Mount EBS volume and transfer data
    ssh -o "StrictHostKeyChecking no" -i "$KEY" "$ssh" bash <<EOF
        sudo mkdir -p /mnt/EBS
        sudo mount "$dev_path" /mnt/EBS
        sudo mkdir -p /mnt/EBS/DATA
        sudo chmod -R 777 /mnt
EOF

    local snap_id="$input"

    if [[ "$CREATE_VOL" == true ]]
    then
        scp -i "$KEY" "$input"/*.fastq.gz "$ssh":/mnt/EBS/DATA
        scp -i "$KEY" "$input"/config.yaml "$ssh":/mnt/EBS/DATA

        local snap=$(
            aws ec2 create-snapshot \
                --description "$snap_name" \
                --volume-id "$vol" \
	        | grep -E -o "snap\-[[:alnum:]]+"
    	    )
    fi


    # Return ID for saved snapshot
    echo "$snap"
}



terminate_ec2() {
    local ec2="$1"
    local vol="$2"
    local snap="$3"

    # Terminate EC2 instance
    completed_snap() {
        aws ec2 describe-snapshots \
            --snapshot-ids "$snap" \
            --filters Name=status,Values=completed \
            | grep -E -o "$snap"
    }

    check_state completed_snap

    aws ec2 terminate-instances \
        --instance-ids "$ec2"

    terminated_ec2() {
        aws ec2 describe-instances \
            --instance-id "$ec2" \
            --filters Name=instance-state-name,Values=terminated \
            | grep -o "$ec2"
    }

    check_state terminated_ec2


    # Delete EBS volume
    aws ec2 delete-volume \
        --volume-id "$vol"

    echo """

Data have been saved to snapshot $snap.

Samples can be re-run using the following command:
$0 -i $snap -o $OUTPUT -k $KEY

    """
}



main() {

    # Set project name
    project_name="$PROJECT"_$(date +%Y%m%d-%H:%M:%S)

    # Launch EC2 instance
    ec2_id=$(
        launch_ec2 \
            "$AMI" \
            "$EC2_TYPE" \
            "$ZONE" \
            "$SECURITY_GROUP" \
            "$SUBNET"
    )

    # Create EBS volume
    vol_id=$(
        create_ebs \
            "$ec2_id" \
            "$VOLUME_SIZE" \
            "$ZONE"
    )

    # Retrieve public DNS for ssh
    # Public DNS is not listed in run-instances output
    pub_dns=$(
        aws ec2 describe-instances \
            --instance-id "$ec2_id" \
            | grep -E -o "ec2\-[[:alnum:]\.\-]+compute.amazonaws.com" \
            | head -n 1
    )

    ec2_ssh="$USER@$pub_dns"

    # Mount EBS volume
    snap_id=$(
        transfer_data \
            "$INPUT" \
            "$vol_id" \
            "$VOLUME_SIZE" \
            "$ec2_ssh" \
	    "$project_name"
    )



    # Run cellranger
    ssh -i "$KEY" "$ec2_ssh" \
        bash /home/"$USER"/PIPELINE/snakecharmer.sh

    scp -r -i "$KEY" "$ec2_ssh":/home/"$USER"/PIPELINE/RESULTS/logs "$OUTPUT"
    #scp -r -i "$KEY" "$ec2_ssh":/home/"$USER"/PIPELINE/RESULTS/* "$OUTPUT"     # NEED TO CHANGE THIS!!!!!

    # REMOVE AFTER TESTING!!!!
    #exit 0



    # Terminate EC2 instance
    terminate_ec2 \
        "$ec2_id" \
        "$vol_id" \
        "$snap_id"
}



main



