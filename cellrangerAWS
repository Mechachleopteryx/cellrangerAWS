#! /bin/bash

set -o nounset -o pipefail -o errexit


# Inputs
INPUT="none"
CONFIG="none"
S3="none"
KEY="none"
FORCE_CLEAN=true


# Defaults
MANUAL_MODE=false
CLEAN_UP=false
TRANSFER_DATA=true
EC2_TYPE="c5.12xlarge"
AMI="ami-0673cf28b2cf6abc4"
ZONE="us-west-2a"
SECURITY_GROUP="sg-00cf9318d9719735d"
SUBNET="subnet-083a3a855e543ee1c"


# Usage message
usage() {
    echo """
USAGE
"$0" [OPTIONS]

OPTIONS
-i, path to local directory or S3 bucket containing fastq files.
-c, path to config.yaml ...OR S3 BUCKET.
-k, path to AWS private key.

-h, display this message.
-s, name of an S3 bucket to transfer data to, if the bucket does not exist a new one will be created.
-t, EC2 instance type (default is "$EC2_TYPE").
-a, ID for machine image configured to run cellranger (default is "$AMI").
-f, terminate running instances/volumes and start new job.
-m, run in manual mode, this transfers data to an EC2 instance and exits.
    """
}





# Parse arguments =============================================================

while getopts ":hi:c:s:k:t:a:fm" args
do
    case "$args" in
        h)
            usage
            exit 0
            ;;
        i) 
            INPUT="$OPTARG"

            if [[ "$INPUT" =~ ^s3://.+ ]]
            then
                TRANSFER_DATA=false
                S3="$INPUT"
            fi
            ;;
        c) CONFIG="$OPTARG" ;;
        s) S3="$OPTARG" ;;
        k) KEY="$OPTARG" ;;
        t) EC2_TYPE="$OPTARG" ;;
        a) AMI="$OPTARG" ;;
        f) CLEAN_UP=true ;;
        m) MANUAL_MODE=true ;;
        :)
            echo -e "\nERROR: -$OPTARG requires an argument"

            usage
	    exit 1
            ;;
	*) 
            usage
	    exit 1
            ;;
    esac
done

if [[ "$INPUT" == "none" || "$CONFIG" == "none" || "$KEY" == "none" ]]
then
    echo -e "\nERROR: Arguments are required for -i, -c, and -k."

    usage
    exit 1
fi





# Check instance/volume status =================================================

get_time() {
    echo "["$(date "+%F %T")"]"
}

check_status() {
    local input_fun="$1"
    local id="$2"
    local num=15
    local id_regex=$(echo $2 | sed 's/ /\|/g')

    if [[ "$#" == 3 ]]
    then
        local num="$3"
    fi

    echo -e "\n$(get_time) Checking for $input_fun "$id"..."

    for i in $(seq 1 "$num")
    do   
        sleep 20

        if "$input_fun" "$id" | grep -E --quiet "$id_regex"
        then
            return 0
        fi
    done

    echo -e "\n$(get_time) ERROR: Timed out waiting for $input_fun "$id"."

    exit 1
}

running_ec2() {
    aws ec2 describe-instances \
        --instance-ids $1 \
        --filters Name=instance-state-name,Values=running
}

available_vol() {
    aws ec2 describe-volumes \
        --volume-ids $1 \
        --filters Name=status,Values=available
}

attached_vol() {
    aws ec2 describe-volumes \
        --volume-ids $1 \
        --filters Name=attachment.status,Values=attached
}

terminated_ec2() {
    aws ec2 describe-instances \
        --instance-ids $1 \
        --filters Name=instance-state-name,Values=terminated
}





# Check for the undead =========================================================

check_for_undead() {
    local kill_job=false
    

    # Terminate EC2 instances from previous jobs
    local running_ec2s=$(
        aws ec2 describe-instances \
            --filters Name=instance-state-name,Values=running
    )

    if [[ "$running_ec2s" =~ "InstanceId" ]]
    then
        local ec2_ids=$(
            echo "$running_ec2s" \
	        | grep "InstanceId" \
                | grep -E -o "i\-[[:alnum:]]+"
        )

	if "$CLEAN_UP"
        then
            clean_up "$ec2_ids"
	
	else
            echo -e "\n$(get_time) ERROR: An EC2 instance from a previous job is still running, to terminate this instance and start a new job, include the -f option."

	    local kill_job=true
        fi
    fi
    


    # Delete EBS volumes from previous jobs
    available_vols=$(
        aws ec2 describe-volumes \
            --filters Name=status,Values=available,in-use \
    )

    if [[ "$available_vols" =~ "VolumeId" ]]
    then
        local vol_ids=$(
	    echo "$available_vols" \
                | grep "VolumeId" \
                | grep -E -o "vol\-[[:alnum:]]+"
	)

	if "$CLEAN_UP"
        then
            clean_up "$vol_ids"
        
        else
            echo -e "\n$(get_time) ERROR: An EBS volume from a previous job is still available, to delete this volume and start a new job, include the -f option."

	    local kill_job=true
        fi
    fi

    if "$kill_job"
    then
        exit 1
    fi
}





# Transfer data to S3 bucket ===================================================

transfer_to_s3() {
    local input="$1"
    local s3="$2"

    if ! aws s3 ls "$s3" > /dev/null
    then
        bucket_name=$(
            echo "$s3" \
                | grep -E -o "s3://[[:alnum:]\-]+" \
                | sed 's/s3:\/\///g'
        )

        aws s3api create-bucket \
            --bucket "$bucket_name"
    fi

    for fq in "$input"*.fastq.gz
    do
        aws s3 cp "$fq" "$s3"
    done
}





# Launch EC2 instance ==========================================================
# When using default VPC the instance does not have internet access. To resolve
# this create new VPC, security group, subnet, and internet gateway. Activate
# public IP for subnet, activate public DNS for VPC, attach VPC to internet
# gateway, modify route table for VPC.

launch_ec2() {
    local s3="$1"
    local ami="$2"
    local ec2_type="$3"
    local zone="$4"
    local key_name=$(basename -s .pem "$KEY")

    echo -e "\n$(get_time) Launching EC2 $EC2_TYPE instance..."



    # Get total size of fastqs in S3 bucket
    local data_size=$(
        aws s3 ls "$s3" --summarize --human-readable \
            | grep "Total Size" \
            | grep -E -o "[0-9].+$"
    )

    local vol_size=$(
        echo "$data_size" \
            | grep -E -o "^[0-9]+"
    )

    if [[ ! "$data_size" =~ [0-9\.]+.[G|T]iB ]]
    then
        local vol_size=10
    fi

    local vol_size=$(expr "$vol_size" \* 3 + 100)

    root_dev=$(
        aws ec2 describe-images \
            --image-id "$ami" \
            | grep -B 1 "Ebs" \
            | grep -E -o "/dev/[[:alnum:]]+"
    )



    # Launch EC2 instance
    # Public DNS is not listed in run-instances output, this must be retrieved
    # separately
    ec2_id=$(
        aws ec2 run-instances \
            --instance-type "$ec2_type" \
            --image-id "$ami" \
            --placement AvailabilityZone="$zone" \
            --block-device-mapping DeviceName="$root_dev",Ebs={VolumeSize="$vol_size"} \
            --security-group-ids "$SECURITY_GROUP" \
            --subnet-id "$SUBNET" \
            --key-name "$key_name" \
            --associate-public-ip-address \
            | grep -E -o "InstanceId\": \"i\-[[:alnum:]]+" \
            | grep -E -o "i\-[[:alnum:]]+"
    )

    check_status running_ec2 "$ec2_id"

    echo -e "\n$(get_time) EC2 instance $ec2_id has been successfully launched."
}





# Retrieve public DNS for EC2 instance and check connectivity ==================

get_dns() {
    local ec2="$1"

    echo -e "\n$(get_time) Attempting to make contact with EC2 instance $ec2..."



    # Retrieve public IP to check connectivity
    local ip=$(
        aws ec2 describe-instances \
            --instance-id "$ec2" \
            | grep -E "PublicIpAddress" \
            | grep -E -o "[0-9\.]+"
    )



    # Ping IP
    for i in $(seq 1 20)
    do
        local packet_loss=$(
            ping -c 10 "$ip" \
                | grep -E -o "[0-9]+% packet loss" \
                | grep -E -o "[0-9]+"
        )

        # If IP responds to ping, return public DNS
        if [[ "$packet_loss" < 100 ]]
        then
            local dns=$(
                aws ec2 describe-instances \
                    --instance-id "$ec2" \
                    | grep -E -o "ec2\-[[:alnum:]\.\-]+compute.amazonaws.com" \
                    | head -n 1
            )

            EC2_SSH="ubuntu@$dns"

	    sleep 10

            echo -e "\n$(get_time) Connection has been established with EC2 instance $ec2, use the following command to manually connect:"
	    echo -e "ssh -i $KEY $EC2_SSH\n"

            return 0
        fi
    done



    # If IP does not respond to ping, terminate instance
    echo -e "\n$(get_time) ERROR: Unable to contact EC2 instance $ec2."

    clean_up "$ec2"

    exit 1
}





# Create and mount EBS volume on EC2 instance ==================================
# Since snapshots are no longer being saved, it might be better to adjust the
# size of the root volume when launching the instance instead of attaching an
# additional volume

create_ebs() {
    local input="$1"
    local ec2="$2"
    local zone="$3"
    local s3="$4"

    echo -e "\n$(get_time) Creating EBS volume..."



    # Get total file size
    local data_size=$(
        aws s3 ls "$s3" --summarize --human-readable \
            | grep "Total Size" \
            | grep -E -o "[0-9].+$"
    )

    local vol_size=$(
        echo "$data_size" \
            | grep -E -o "^[0-9]+"
    )

    local vol_size=$(expr "$vol_size" \* 3)

    if ! echo "$data_size" | grep -E "GiB|TiB" --quiet
    then
        local vol_size=10
    fi

    if [[ "$vol_size" < 10 ]]
    then
        local vol_size=10
    fi



    # Get list of attached devices, need this to identify attached EBS volume
    local old_devs=$(
        ssh -o "StrictHostKeyChecking no" -i "$KEY" "$EC2_SSH" \
            sudo fdisk -l \
                | grep -E -o "/dev/[[:alnum:]]+" \
                2>&1
    )

    # Keep old_devs unquoted here
    local old_devs=$(
        echo $old_devs \
            | sed 's/ /|/g'
    )



    # Create EBS volume
    vol_id=$(
        aws ec2 create-volume \
            --size "$vol_size" \
            --availability-zone "$zone" \
            | grep -E -o "vol\-[[:alnum:]]+"
    )
        
    check_status available_vol "$vol_id"



    # Attach EBS volume
    aws ec2 attach-volume \
        --instance-id "$ec2" \
        --volume-id "$vol_id" \
        --device /dev/sdh \
        > /dev/null

    check_status attached_vol "$vol_id"



    # Identify device path for EBS volume
    local new_devs=$(
        ssh -i "$KEY" "$EC2_SSH" \
            sudo fdisk -l \
                | grep -E "^Disk .+$vol_size GiB" \
                | grep -E -o "/dev/[[:alnum:]]+" \
                2>&1
    )
    
    local dev_path=$(
        echo "$new_devs" \
            | grep -E -v "$old_devs"
    )



    # Format and mount EBS volume
    ssh -i "$KEY" "$EC2_SSH" bash <<EOF
        sudo parted "$dev_path" mklabel gpt > /dev/null 2>&1
        sudo parted -a opt "$dev_path" mkpart primary ext4 0% 100% > /dev/null 2>&1
        sudo mkfs.ext4 -F "$dev_path" > /dev/null 2>&1

        sudo mkdir -p /mnt/EBS
        sudo mount "$dev_path" /mnt/EBS
        sudo mkdir -p /mnt/EBS/DATA
        sudo chmod -R 777 /mnt/EBS
EOF

    echo -e "\n$(get_time) EBS volume $vol_id ($vol_size GB) has been mounted to EC2 instance $ec2."
}





# Transfer data from S3 bucket to EBS volume ==================================

transfer_to_ec2() {
    local s3="$1"
    #local vol="$2"



    # Configure AWS on EC2 instance
    local iam_id=$(
        cat "$HOME/.aws/credentials" \
            | grep -A 2 "default" \
            | grep "aws_access_key_id" \
	    | grep -E -o "[[:alnum:]]+$"
    )

    local iam_key=$(
        cat "$HOME/.aws/credentials" \
            | grep -A 2 "default" \
            | grep "aws_secret_access_key" \
            | grep -E -o "[[:alnum:]/\+]+$"
    )

    local aws="~/.local/bin/aws"

    ssh -o "StrictHostKeyChecking no" -i "$KEY" "$EC2_SSH" \
        "$aws" configure set aws_access_key_id "$iam_id"

    ssh -i "$KEY" "$EC2_SSH" \
        "$aws" configure set aws_secret_access_key "$iam_key"



    # Transfer files to EBS volume
    local s3_fqs=$(
        aws s3 ls "$s3" \
            | grep -E -o "[[:alnum:]_\-\.]+.fastq.gz"
    )

    echo -e "\n$(get_time) Transferring the following files from S3 bucket $s3 to EC2 instance:"
    echo "$s3_fqs"

    scp -i "$KEY" "$CONFIG" "$EC2_SSH:~/" \
        > /dev/null

    # Leave s3_fqs unquoted
    for fq in $s3_fqs
    do 
        ssh -i "$KEY" "$EC2_SSH" \
            "$aws" s3 cp "$s3/$fq" "~/DATA" \
                > /dev/null
    done
   
    wait

    sleep 30
}





# Run Cell Ranger ==============================================================

run_cellranger() {
    local s3="$1"

    aws="~/.local/bin/aws"

    echo -e "\n$(get_time) Beginning Cell Ranger run..."

    ssh -i "$KEY" "$EC2_SSH" \
        bash "~/PIPELINE/snakecharmer.sh"

    echo -e "\n$(get_time) Cell Ranger run has completed, transferring results to S3 bucket $s3."
    
    ssh -i "$KEY" "$EC2_SSH" \
        "$aws" s3 cp "~/RESULTS" "$s3" --recursive
}





# Terminate EC2 instance and delete EBS volume =================================

clean_up() {


    # Terminate EC2 instance
    if [[ "$1" =~ ^i\-[[:alnum:]]+ ]]
    then
        local ec2="$1"

        echo -e "\n$(get_time) Terminating EC2 instance "$ec2"..."

        aws ec2 terminate-instances \
            --instance-ids $ec2 \
            > /dev/null

        check_status terminated_ec2 "$ec2" 
	
	# Keep this quoting pattern so multiple IDs are displayed on one line
        echo -e "\n$(get_time) EC2 instance "$ec2" has been terminated."   
    fi



    # Delete EBS volume
    if [[ "$1" =~ ^vol\-[[:alnum:]]+ ]] || [[ "$#" == 2 ]]
    then
        local vol="$1"

	if [[ "$#" == 2 ]]
        then
            local vol="$2"
        fi

        # Delete EBS volume
        echo -e "\n$(get_time) Deleting EBS volume "$vol"..."

        aws ec2 delete-volume \
            --volume-id $vol \
            > /dev/null

	echo -e "\n$(get_time) EBS volume "$vol" has been deleted."
    fi
}





# Main function ================================================================

main() {
  
    # Terminate instances/volumes from previous runs
    if "$FORCE_CLEAN"
    then
        check_for_undead
    fi



    # Transfer data to S3 bucket
    if "$TRANSFER_DATA"
    then
        transfer_to_s3 \
            "$INPUT" \
            "$S3"
    fi



    # Launch EC2 instance and retrieve ec2_id
    launch_ec2 \
        "$S3" \
        "$AMI" \
        "$EC2_TYPE" \
        "$ZONE"



    # Check EC2 instance connectivity and retrieve EC2_SSH
    get_dns "$ec2_id"



    # Create EBS volume and retrieve vol_id
    #create_ebs \
    #    "$INPUT" \
    #    "$ec2_id" \
    #    "$ZONE" \
    #    "$S3"



    # Transfer data from S3 bucket to EC2 instance
    transfer_to_ec2 "$S3" 

    if "$MANUAL_MODE"
    then
        exit 0
    fi



    # Run Cell Ranger
    run_cellranger "$S3"



    # Terminate EC2 instance
    clean_up "$ec2_id"
}



main



